{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "jUgJ75rKw7GU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3C4LF4hgxDdg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pregunta 2\n"
      ]
    },
    {
      "metadata": {
        "id": "tYjI2RQPwnl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "d1c05ae0-2556-49f1-f36b-6b10acf8f04b"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "!pip install gensim\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(11235813)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sn\n",
        "\n",
        "# Tensorflow & Keras imports\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, RepeatVector, TimeDistributed, Dense, Embedding, Flatten, Activation, Permute, Lambda, CuDNNGRU\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "# model saving\n",
        "!sudo apt-get install libhdf5-serial-dev\n",
        "import h5py\n",
        "\n",
        "from google.colab import files\n",
        "!git clone https://github.com/TattooeDeer/T3-ANN.git\n",
        "%cd T3-ANN\n",
        "!ls\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/f3/37504f07651330ddfdefa631ca5246974a60d0908216539efda842fd080f/gensim-3.5.0-cp36-cp36m-manylinux1_x86_64.whl (23.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.5MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/3d/5f3a9a296d0ba8e00e263a8dee76762076b9eb5ddc254ccaa834651c8d65/smart_open-1.6.0.tar.gz\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 8.7MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/d4/5dc7ec1a9ed198ea88f9a10092e3577715b374e15e0c9b44589c97fbea8e/boto3-1.8.3-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 19.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.8.13)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Collecting botocore<1.12.0,>=1.11.3 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/22/c5d08c2aaa4f8606c0b1cdee87a60ccad201865011b05af4c3dbe2c04e26/botocore-1.11.3-py2.py3-none-any.whl (4.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.6MB 7.4MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 16.0MB/s \n",
            "\u001b[?25hCollecting docutils>=0.10 (from botocore<1.12.0,>=1.11.3->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 20.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.12.0,>=1.11.3->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/73/f1/9b/ccf93d4ba073b6f79b1ed9df68ab5ce048d8136d0efcf90b30\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.8.3 botocore-1.11.3 bz2file-0.98 docutils-0.14 gensim-3.5.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/bin/sh: 1: sudo: not found\n",
            "Cloning into 'T3-ANN'...\n",
            "remote: Counting objects: 12, done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 12 (delta 2), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (12/12), done.\n",
            "/content/T3-ANN\n",
            "Enunciado_T3.ipynb  LICENSE  README.md\tTarea3.ipynb  test_Q.csv  train_Q-A.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VL42xkHl4Jjf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## a) Carga de los datos en el entorno y análisis descriptivo"
      ]
    },
    {
      "metadata": {
        "id": "LY_FvybPw37X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0c0fe0d4-ee3d-4d2f-eda4-b286d8f62e93"
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_Q-A.csv')\n",
        "test = pd.read_csv('test_Q.csv')\n",
        "\n",
        "print('Train shape: {0}'.format(train.shape))\n",
        "print('Test shape: {0}'.format(test.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape: (86821, 3)\n",
            "Test shape: (11873, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fu6HsKm5zWi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0b4dff42-1482-46c6-c323-ce86eab655a6"
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>in the late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>Houston, Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id  \\\n",
              "0  56be85543aeaaa14008c9063   \n",
              "1  56be85543aeaaa14008c9065   \n",
              "2  56be85543aeaaa14008c9066   \n",
              "3  56bf6b0f3aeaaa14008c9601   \n",
              "4  56bf6b0f3aeaaa14008c9602   \n",
              "\n",
              "                                            question               answer  \n",
              "0           When did Beyonce start becoming popular?    in the late 1990s  \n",
              "1  What areas did Beyonce compete in when she was...  singing and dancing  \n",
              "2  When did Beyonce leave Destiny's Child and bec...                 2003  \n",
              "3      In what city and state did Beyonce  grow up?        Houston, Texas  \n",
              "4         In which decade did Beyonce become famous?           late 1990s  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "bxh7VZd7w34l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a177c5e4-f001-425e-f5e4-63ca60461e1f"
      },
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>86821</td>\n",
              "      <td>86821</td>\n",
              "      <td>86821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>86821</td>\n",
              "      <td>86769</td>\n",
              "      <td>64763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>572b6eeb34ae481900deae0d</td>\n",
              "      <td>When did Nasser die?</td>\n",
              "      <td>three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id              question answer\n",
              "count                      86821                 86821  86821\n",
              "unique                     86821                 86769  64763\n",
              "top     572b6eeb34ae481900deae0d  When did Nasser die?  three\n",
              "freq                           1                     2    231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "3rG5hv1Kzg8i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Al parecer el primer problema que observamos es que para preguntas cuya respuesta es cuantitativa, la respuesta dada es expresada en algunos casos en palabras y en otros en números, nuestro primer intento de solucionar esto será explorar si se cumplen patrones para cada tipo de respuesta, por ejemplo, solo las fechas se responden con números u otra regla similar.\n"
      ]
    },
    {
      "metadata": {
        "id": "pVnKEusYw31f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "6fc0724e-dccc-4fc7-f543-b156688c4d07"
      },
      "cell_type": "code",
      "source": [
        "test.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11873</td>\n",
              "      <td>11873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>11873</td>\n",
              "      <td>11864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>5725ec8289a1e219009ac0b2</td>\n",
              "      <td>Who designed Salamanca?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id                 question\n",
              "count                      11873                    11873\n",
              "unique                     11873                    11864\n",
              "top     5725ec8289a1e219009ac0b2  Who designed Salamanca?\n",
              "freq                           1                        2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "4tkbfa8izgFj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se observa algo interesante analizando la cantidad de valores únicos y de conteo de las columnas `question` y  `answer`: La cantidad de ocurrencias únicas no es igual a la cantidad de registros totales, lo que puede indicar que quizás hay preguntas/respuestas repetidas en el dataset. Se observa un comportamiento similar en el conjunto de test aunque en mucho menor medida"
      ]
    },
    {
      "metadata": {
        "id": "MUg026sAzgIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "5b6ac03b-f2ae-4a9d-e389-b164cdc90e93"
      },
      "cell_type": "code",
      "source": [
        "print('10 preguntas más populares:\\n')\n",
        "print(train[\"question\"].value_counts().head(10))\n",
        "print('\\n ----------------------------------------------------------\\n')\n",
        "print('10 respuestas más populares:\\n')\n",
        "print(train[\"answer\"].value_counts().head(10))\n",
        "print('\\n ----------------------------------------------------------\\n')\n",
        "print('10 preguntas más populares (Conjunto de test):\\n')\n",
        "print(test[\"question\"].value_counts().head(10))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 preguntas más populares:\n",
            "\n",
            "When did Nasser die?                                            2\n",
            "Who first observed the photoelectric effect?                    2\n",
            "What years did the civil war take place?                        2\n",
            "In what year did Chopin become a French citizen?                2\n",
            "What country was the largest aid donor to China?                2\n",
            "What was the name of the treaty that ended the war?             2\n",
            "What is the state song of New York?                             2\n",
            "When did the Sex Pistols break up?                              2\n",
            "How many children did Queen Victoria and Prince Albert have?    2\n",
            "Where was Chopin's last public performance?                     2\n",
            "Name: question, dtype: int64\n",
            "\n",
            " ----------------------------------------------------------\n",
            "\n",
            "10 respuestas más populares:\n",
            "\n",
            "three    231\n",
            "two      206\n",
            "four     171\n",
            "five     133\n",
            "six       90\n",
            "2007      87\n",
            "2006      85\n",
            "2010      75\n",
            "2009      71\n",
            "seven     71\n",
            "Name: answer, dtype: int64\n",
            "\n",
            " ----------------------------------------------------------\n",
            "\n",
            "10 preguntas más populares (Conjunto de test):\n",
            "\n",
            "Who designed Salamanca?                                  2\n",
            "What are the main sources of primary law?                2\n",
            "When was James Hutton born?                              2\n",
            "What is the CJEU's duty?                                 2\n",
            "Who conceptualized the piston?                           2\n",
            "Where does heat rejection occur in the Rankine cycle?    2\n",
            "In what sector are jobs beginning to increase?           2\n",
            "In what sector are jobs beginning to decrease?           2\n",
            "What is the population of Los Angeles?                   2\n",
            "When did Victoria approve a referendum?                  1\n",
            "Name: question, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qx826njWzgKh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Las preguntas que más se repiten lo hacen a lo más 2 veces cada una. En cuanto a las respuestas, predominan aquellas que son números escritos como palabras, asi como también números escritos como tal los cuales aprecen ser fechas debido a la cantidad de dígitos y la magnitud que presentan.\n",
        "\n",
        "Lo anterior puede ser en respuesta a un sesgo en la selección de preguntas.\n",
        "\n",
        "Finalmente, se debe notar que el conjunto de test está compuesto solo por preguntas, lo que significa que, de utilizar los conjuntos de la forma en la que están, tendremos un entrenamiento supervisado pero tendremos que encontrar una métrica nueva para evaluar el desempeño final de la máquina.\n",
        "\n",
        "## b) Preprocesamiento\n",
        "\n",
        "Ahora se procederá a preprocesar ambos conjuntos con el objetivo de mejorar el desempeño que tenga la futura máquina al ingerirlos en el entrenamiento.\n",
        "Se _tokenizarán_ las preguntas y respuestas del conjunto de entrenamiento y de test, no realizando mayor modificación de las palabras dado que después necesitaremos reconstruir las oraciones."
      ]
    },
    {
      "metadata": {
        "id": "MnaFR0FIw3yF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_questions = [word_tokenize(sentence.lower()) for sentence in train[\"question\"]] #or processing\n",
        "test_questions = [word_tokenize(sentence.lower()) for sentence in  test[\"question\"]]\n",
        "train_answers = [word_tokenize(sentence) for sentence in train[\"answer\"]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSPwafIP39XZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## c) Vocabulario\n",
        "\n",
        "Ahora, se procede a crear un vocabulario para codificar las palabras en las respuestas a generar, esta aproximación nos servirá para paliar el problema mencionado en el punto *a)*, de que no tenemos las respuestas correctas para el conjunto de test."
      ]
    },
    {
      "metadata": {
        "id": "5j3u0M6n39aE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fdb91be4-ad58-491a-80ea-cdf3859ca335"
      },
      "cell_type": "code",
      "source": [
        "# Respuestas\n",
        "vocab_answer = set()\n",
        "for sentence in train_answers:\n",
        "  for word in sentence:\n",
        "    vocab_answer.add(word)\n",
        "vocab_answer = [\"#end\"] + list(vocab_answer)\n",
        "print('Posibles palabras para respuestas: ', len(vocab_answer))\n",
        "vocabA_indices = {c: i for i, c in enumerate(vocab_answer)}\n",
        "indices_vocabA = {i: c for i, c in enumerate(vocab_answer)}\n",
        "\n",
        "# Preguntas: Train\n",
        "vocab_question = set()\n",
        "for sentence in train_questions:\n",
        "  for word in sentence:\n",
        "    vocab_question.add(word)\n",
        "vocab_question = [\"#end\"] + list(vocab_question)\n",
        "print('Posibles palabras para preguntas (train): ', len(vocab_question))\n",
        "vocabQTrain_indices = {c: i for i, c in enumerate(vocab_question)}\n",
        "indices_vocabQTrain = {i: c for i, c in enumerate(vocab_question)}\n",
        "\n",
        "print('Diferencia en la cantidad de palabras que componen las preguntas y respuestas (train sets): ', \n",
        "      abs(len(vocab_answer) - len(vocab_question)))\n",
        "\n",
        "# Preguntas: Test\n",
        "vocab_question = set()\n",
        "for sentence in test_questions:\n",
        "  for word in sentence:\n",
        "    vocab_question.add(word)\n",
        "vocab_question = [\"#end\"] + list(vocab_question)\n",
        "print('Posibles palabras para preguntas (test): ', len(vocab_question))\n",
        "vocabQTest_indices = {c: i for i, c in enumerate(vocab_question)}\n",
        "indices_vocabQTest = {i: c for i, c in enumerate(vocab_question)}\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Posibles palabras para respuestas:  47423\n",
            "Posibles palabras para preguntas (train):  39482\n",
            "Diferencia en la cantidad de palabras que componen las preguntas y respuestas (train sets):  7941\n",
            "Posibles palabras para preguntas (test):  10322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a32CLkBA39cc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El vocabulario de palabras que componen las respuestas tiene _7941_ elementos más que el que compone las preguntas, esto puede hacer que hayan palabras encontradas en preguntas asociadas a varias palabras de respuesta, haciendo más dificil el discernir la respuesta correcta. Por otro lado, se debe notar la pequeña cantidad de palabras que componen el vocabulario de test."
      ]
    },
    {
      "metadata": {
        "id": "g5mWynT339fD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## d) Codificación de tokens y padding\n",
        "\n",
        "Aplicaremos una codificación tipo *one-hot vector* sobre los tokens, calcularemos el largo máximo que puede tener una respuesta y una pregunta y reformularemos las secuencias de entrada del modelo agregandoles un padding al final, esto hará que el tamaño de input sea constante. Para las preguntas se rellenará con '0' (recordar que las palabras estan indexadas y tokenizadas), mientras que para las respuestas se rellenará con el carácter definido *'#end'* que indica cuando la pregunta ha sido respondida.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gWfUQCX139jE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input and output to onehotvector\n",
        "X_answers = [[vocabA_indices[palabra] for palabra in sentence] for sentence in train_answers]\n",
        "X_test_Q = [[vocabQTest_indices[palabra] for palabra in sentence] for sentence in test_questions]\n",
        "X_train_Q = [[vocabQTrain_indices[palabra] for palabra in sentence] for sentence in train_questions]\n",
        "\n",
        "# padding\n",
        "max_input_length = np.max(list(map(len, train_questions)))\n",
        "max_output_length = np.max(list(map(len, train_answers)))\n",
        "\n",
        "X_train_Q = sequence.pad_sequences(X_train_Q, maxlen = max_input_length,\n",
        "                                        padding = 'post', value = 0)\n",
        "X_test_Q = sequence.pad_sequences(X_test_Q, maxlen = max_input_length,\n",
        "                                        padding = 'post', value = 0)\n",
        "X_answers = sequence.pad_sequences(X_answers, maxlen = max_output_length,\n",
        "                                        padding = 'post', value = vocabA_indices['#end'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y985lm4O39lm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## e) Modelo *Encoder-Decoder* con módulos de atención\n",
        "\n",
        "Utilizaremos un encoder basado en GRU."
      ]
    },
    {
      "metadata": {
        "id": "x6DiPDzP39oE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Encoder-Decoder modelo\n",
        "length_output = max_output_length\n",
        "hidden_dim = 128\n",
        "\n",
        "embedding_vector = 64\n",
        "encoder_input = Input(shape = (max_input_length, ))\n",
        "embedded = Embedding(input_dim = len(vocabQTrain_indices), output_dim = embedding_vector,\n",
        "                    input_length = max_input_length)(encoder_input)\n",
        "encoder = CuDNNGRU(hidden_dim, return_sequences = True)(embedded)\n",
        "\n",
        "attention = TimeDistributed(Dense(max_output_length, activation = 'tanh'))(encoder)\n",
        "\n",
        "# softmax a las atenciones sobre todo T\n",
        "attention = Permute([2, 1])(attention)\n",
        "attention = Activation('softmax')(attention)\n",
        "attention = Permute([2, 1])(attention)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_t_mw8tR39qx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Aplicacion de la atencion al modelo\n",
        "def attention_multiply(vects):\n",
        "  encoder, attention = vects\n",
        "  return K.batch_dot(attention, encoder, axes = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fhK96YZB39hg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_representation = Lambda(attention_multiply)([encoder, attention])\n",
        "decoder = CuDNNGRU(hidden_dim, return_sequences= True)(sent_representation)\n",
        "probabilities = TimeDistributed(Dense(len(vocab_answer), activation = 'softmax'))(decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tNQ7RXP1XcTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "f1af9f90-8e9d-4be4-a5e6-88fffc3dc57c"
      },
      "cell_type": "code",
      "source": [
        "model = Model(encoder_input, probabilities)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam')\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 60)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 60, 64)       2526848     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnngru_1 (CuDNNGRU)          (None, 60, 128)      74496       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 60, 46)       5934        cu_dnngru_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 46, 60)       0           time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 60)       0           permute_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_2 (Permute)             (None, 60, 46)       0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 46, 128)      0           cu_dnngru_1[0][0]                \n",
            "                                                                 permute_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnngru_2 (CuDNNGRU)          (None, 46, 128)      99072       lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 46, 47423)    6117567     cu_dnngru_2[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 8,823,917\n",
            "Trainable params: 8,823,917\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dfmoHD1_YVU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## f) Entrenamiento del modelo\n",
        "\n",
        "Se entrenará el modelo con 10 epochs con tamaño de batch 64"
      ]
    },
    {
      "metadata": {
        "id": "adYhTEB2YtX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "748023fd-e020-4ad7-9157-5a0e5178cf89"
      },
      "cell_type": "code",
      "source": [
        "X_answers = X_answers.reshape(X_answers.shape[0], X_answers.shape[1],1)\n",
        "X_answers.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86821, 46, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "bzDkoGONY8Cu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BS = 64\n",
        "model.fit(X_train_Q, X_answers, epochs = 10, batch_size = BS,\n",
        "               validation_split = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-0aZ2d359MB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.save('attention_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_krsO_gfFOdD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model('attention_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9_vauVFFOm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "be1f0d18-e112-422b-c3e1-923e4c16a919"
      },
      "cell_type": "code",
      "source": [
        "max_output_length"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cbc34c1d0cb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_output_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'max_output_length' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4Q2s2436ZNDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## g) Predicción del modelo\n",
        "\n",
        "Evaluaremos ahora las predicciones del modelo a traves del modelamiento de la distribución de probabilidad de las respuestas, basandonos en la frecuencia de ocurrencia de los tokens encontrados en las mismas.\n"
      ]
    },
    {
      "metadata": {
        "id": "TFpg3tZ__uWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5bb091b-2c85-444f-ac96-4a247176f93d"
      },
      "cell_type": "code",
      "source": [
        "model.predict(X_train_Q[1:2]).shape\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 46, 47423)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "BDdUwUMJgpnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "37071b37-5a6f-4cd8-b824-f6e75782220b"
      },
      "cell_type": "code",
      "source": [
        "def predict_words(model, example, diversity):\n",
        "  model = load_model('attention_model.h5')\n",
        "  example = np.array(example)\n",
        "  example.reshape((60,))\n",
        "  prediction = model.predict(example)\n",
        "  return prediction\n",
        "  \n",
        "n = 10\n",
        "for i in range(n):\n",
        "  indexs = np.random.randint(0, len(X_test_Q)-2)\n",
        "  example = X_train_Q[indexs:(indexs+1)]\n",
        "  indexes_answer = predict_words(model, example, 0.85)\n",
        "  question = test['question'][indexs]\n",
        "  print('Pregunta: ', question)\n",
        "  answer = ''\n",
        "  for index in indexes_answer:\n",
        "    print(index)\n",
        "    if (indices_vocabA[index] == '#end'): # fin de la oracion\n",
        "      continue\n",
        "    else:\n",
        "      answer += indices_vocabA[index]+' '\n",
        "  print('Respuesta: ', answer)\n",
        "print('Los ha predecido todos!')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pregunta:  What kind of communication can be implemented?\n",
            "[[2.57918055e-05 4.86640431e-07 1.69777297e-06 ... 1.65017548e-06\n",
            "  4.37102653e-06 6.09286781e-06]\n",
            " [7.85899699e-01 2.20572467e-08 1.90806577e-06 ... 1.51370500e-07\n",
            "  2.85213673e-06 3.44994078e-06]\n",
            " [9.86455917e-01 2.97802716e-09 2.82061791e-07 ... 1.43518593e-08\n",
            "  2.61086885e-08 1.13456355e-08]\n",
            " ...\n",
            " [9.99976516e-01 1.48177166e-13 6.82855786e-11 ... 9.91736315e-13\n",
            "  1.87624677e-12 7.45158763e-13]\n",
            " [9.99981046e-01 1.43173356e-13 6.00178726e-11 ... 7.46433839e-13\n",
            "  1.37678291e-12 6.22006841e-13]\n",
            " [9.99978065e-01 2.48328485e-13 6.99186334e-11 ... 9.38577232e-13\n",
            "  1.82155766e-12 7.41060804e-13]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5b71540e2a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes_answer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices_vocabA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'#end'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# fin de la oracion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "v8zMagSuqsp1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## h) Evaluacion del modelo\n",
        "Para verificar la calidad del modelo, compararemos con el benchmark"
      ]
    },
    {
      "metadata": {
        "id": "Ffqf1bH-qsoI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python evaluate-v2.0.py dev-v2.0.json predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X_awuqAZqslg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dic_predictions = {}\n",
        "for example, id_e in zip(Xtest_question, df_test[\"id\"]): # todos los ejemplos\n",
        "  indexes_answer = predict_words(model, example) # predice palabra en cada instante\n",
        "  answer = \"\"\n",
        "  for index in indexes_answer:\n",
        "    if(indices_vocabA[index] == '#end'): # Final de la oracion\n",
        "      continue\n",
        "    else:\n",
        "      answer += indices_vocabA[index]+\" \"\n",
        "  dic_predictions[id_e] = answer\n",
        "  contador += 1\n",
        "  print('Los ha predecido todos!')\n",
        "  json_save = json.dumps(dic_predictions)\n",
        "  archivo = open('predictions', 'w')\n",
        "  archivo.write(json.save)\n",
        "  archivo.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}